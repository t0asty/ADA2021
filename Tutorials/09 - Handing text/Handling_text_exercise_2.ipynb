{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from helpers.helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling text 2 exercise\n",
    "[Handling text exercisses ADApted drom ADA 2018 final exam]\n",
    "\n",
    "The Sheldon Cooper we all know and love (OK, some of us might not know him, and some might not love him) from the TV series \"The Big Bang Theory\" has gotten into an argument with Leonard from the same TV show. Sheldon insists that he knows the show better than anyone, and keeps making various claims about the show, which neither of them know how to prove or disprove. The two of them have reached out to you ladies and gentlemen, as data scientists, to help them. You will be given the full script of the series, with information on the episode, the scene, the person saying each dialogue line, and the dialogue lines themselves.\n",
    "\n",
    "Leonard has challenged several of Sheldon's claims about the show, and throughout this exam you will see some of those and you will get to prove or disprove them, but remember: sometimes, we can neither prove a claim, nor disprove it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task A: Picking up the shovel\n",
    "\n",
    "**Note: You will use the data you preprocess in this task in all the subsequent ones.**\n",
    "\n",
    "Our friends' argument concerns the entire show. We have given you a file in the `data/` folder that contains the script of every single episode. New episodes are indicated by '>>', new scenes by '>', and the rest of the lines are dialogue lines. Some lines are said by multiple people (for example, lines indicated by 'All' or 'Together'); **you must discard these lines**, for the sake of simplicity. However, you do not need to do it for Q1 in this task -- you'll take care of it when you solve Q2.\n",
    "\n",
    "**Q1**. Your first task is to extract all lines of dialogue in each scene and episode, creating a dataframe where each row has the episode and scene where a dialogue line was said, the character who said it, and the line itself. You do not need to extract the proper name of the episode (e.g. episode 1 can appear as \"Series 01 Episode 01 - Pilot Episode\", and doesn't need to appear as \"Pilot Episode\"). Then, answer the following question: In total, how many scenes are there in each season? We're not asking about unique scenes; the same location appearing in two episodes counts as two scenes. You can use a Pandas dataframe with a season column and a scene count column as the response.\n",
    "\n",
    "**Note: The data refers to seasons as \"series\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>scene_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  scene_count\n",
       "0       1         4126\n",
       "1       2         5223\n",
       "2       3         5028\n",
       "3       4         5596\n",
       "4       5         4829"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_df = {'episode': [], 'scene': [], 'character': [], 'line': []}\n",
    "current_episode = ''\n",
    "current_scene = ''\n",
    "scene_count = 0\n",
    "with open('data/all_scripts.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.replace('\\n', '')\n",
    "        if line[:2] == '>>':\n",
    "            current_episode = line.replace('>>', '')\n",
    "            scene_count = 0\n",
    "        elif line[:1] == '>':\n",
    "            current_scene = line.replace('>', '') + '_' + str(scence_count)\n",
    "            scene_count += 1\n",
    "        else:\n",
    "            speaker, quote = line.split(':', 1)\n",
    "            if speaker not in set(['All', 'Together']):\n",
    "                to_df['character'].append(speaker)\n",
    "                to_df['episode'].append(current_episode)\n",
    "                to_df['scene'].append(current_scene)\n",
    "                to_df['line'].append(quote)\n",
    "df = pd.DataFrame(to_df)\n",
    "df_scene_count = df.copy()\n",
    "df_scene_count['season'] = df['episode'].str.split()\n",
    "df_scene_count['season'] = df_scene_count['season'].apply(lambda x: int(x[1]))\n",
    "df_scene_count = df_scene_count.groupby(['season', 'episode'])['scene'].count()\n",
    "df_scene_count = df_scene_count.reset_index()\n",
    "df_scene_count = df_scene_count.groupby('season')['scene'].sum()\n",
    "df_scene_count = df_scene_count.reset_index().rename(columns={'scene': 'scene_count'})\n",
    "df_scene_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**. Now, let's define two sets of characters: all the characters, and recurrent characters. Recurrent characters are those who appear in more than one episode. For the subsequent sections, you will need to have a list of recurrent characters. Assume that there are no two _named characters_ (i.e. characters who have actual names and aren't referred to generically as \"little girl\", \"grumpy grandpa\", etc.) with the same name, i.e. there are no two Sheldons, etc. Generate a list of recurrent characters who have more than 90 dialogue lines in total, and then take a look at the list you have. If you've done this correctly, you should have a list of 20 names. However, one of these is clearly not a recurrent character. Manually remove that one, and print out your list of recurrent characters. To remove that character, pay attention to the _named character_ assumption we gave you earlier on. **For all the subsequent questions, you must only keep the dialogue lines said by the recurrent characters in your list.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = df.groupby('character')['line'].count()\n",
    "characters = characters[characters >= 90].reset_index()\n",
    "characters = characters['character'].to_list()\n",
    "characters.remove('Man')\n",
    "recurrent_characters = characters\n",
    "len(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B: Read the scripts carefully\n",
    "\n",
    "### Part 1: Don't put the shovel down just yet\n",
    "\n",
    "**Q3**. From each dialogue line, replace punctuation marks (listed in the EXCLUDE_CHARS variable provided in `helpers/helper_functions.py`) with whitespaces, and lowercase all the text. **Do not remove any stopwords, leave them be for all the questions in this task.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>scene</th>\n",
       "      <th>character</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank._0</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>so if a photon is directed through a plane wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank._0</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>agreed  what s your point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank._0</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>there s no point  i just think it s a good id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank._0</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>excuse me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank._0</td>\n",
       "      <td>Receptionist</td>\n",
       "      <td>hang on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 episode                           scene  \\\n",
       "0   Series 01 Episode 01 – Pilot Episode   A corridor at a sperm bank._0   \n",
       "1   Series 01 Episode 01 – Pilot Episode   A corridor at a sperm bank._0   \n",
       "2   Series 01 Episode 01 – Pilot Episode   A corridor at a sperm bank._0   \n",
       "3   Series 01 Episode 01 – Pilot Episode   A corridor at a sperm bank._0   \n",
       "4   Series 01 Episode 01 – Pilot Episode   A corridor at a sperm bank._0   \n",
       "\n",
       "      character                                               line  \n",
       "0       Sheldon   so if a photon is directed through a plane wi...  \n",
       "1       Leonard                         agreed  what s your point   \n",
       "2       Sheldon   there s no point  i just think it s a good id...  \n",
       "3       Leonard                                         excuse me   \n",
       "4  Receptionist                                           hang on   "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df.copy()\n",
    "reg = \"|\\\\\".join(EXCLUDE_CHARS)\n",
    "df_clean['line'] = df_clean['line'].str.replace(reg, ' ', regex=True).str.lower()\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4**. For each term, calculate its \"corpus frequency\", i.e. its number of occurrences in the entire series. Visualize the distribution of corpus frequency using a histogram. Explain your observations. What are the appropriate x and y scales for this plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAD4CAYAAADGmmByAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAASdklEQVR4nO3df6zd9V3H8edrdDI2x4S1IGnBwtao3aIMOsTMH5tEYSwTppt2MdIosTpZ4uJMLNM4/KPJMNlQokNZWFZQB4y5gVFUZMbFBOkuiuPXkE5wdG1o55aBusHK3v5xPnce2nNvD/3cc+89vc9HcnK+532+n+/5vHcaXvv+uN+TqkKSpCP1gqWegCRpuhkkkqQuBokkqYtBIknqYpBIkrqsWuoJLLbVq1fX+vXrl3oakjRV7rnnni9V1ZpR7624IFm/fj0zMzNLPQ1JmipJ/nOu9zy0JUnqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSeqy4v6yvcf6bX/VNf6x971pgWYiScuHeySSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6jKxIElyapJ/SPJQkgeS/Fqrn5jkjiSPtOcThsZcnmRXkoeTnD9UPzvJfe29q5Ok1Y9NclOr351k/aT6kSSNNsk9kgPAu6vqe4FzgcuSbAS2AXdW1Qbgzvaa9t5m4FXABcAHkxzTtnUNsBXY0B4XtPqlwFeq6pXAVcCVE+xHkjTCxIKkqvZW1b+05aeAh4C1wEXAjrbaDuDitnwRcGNVPV1VjwK7gHOSnAIcX1V3VVUB1x80ZnZbtwDnze6tSJIWx6KcI2mHnF4D3A2cXFV7YRA2wElttbXA40PDdrfa2rZ8cP05Y6rqAPBV4OUjPn9rkpkkM/v371+griRJsAhBkuTbgY8D76qqJ+dbdUSt5qnPN+a5haprq2pTVW1as2bN4aYsSXoeJhokSV7IIET+rKr+opWfaIeraM/7Wn03cOrQ8HXAnlZfN6L+nDFJVgEvA7688J1IkuYyyau2AlwHPFRVHxh66zZgS1veAtw6VN/crsQ6ncFJ9Z3t8NdTSc5t27zkoDGz23or8Kl2HkWStEgm+VO7rwN+Hrgvyb2t9h7gfcDNSS4FvgC8DaCqHkhyM/Aggyu+LquqZ9u4dwAfAY4Dbm8PGATVDUl2MdgT2TzBfiRJI0wsSKrqnxh9DgPgvDnGbAe2j6jPAK8eUf86LYgkSUvDv2yXJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVKXiQVJkg8n2Zfk/qHaFUm+mOTe9rhw6L3Lk+xK8nCS84fqZye5r713dZK0+rFJbmr1u5Osn1QvkqS5TXKP5CPABSPqV1XVme3x1wBJNgKbgVe1MR9Mckxb/xpgK7ChPWa3eSnwlap6JXAVcOWkGpEkzW1iQVJVnwa+PObqFwE3VtXTVfUosAs4J8kpwPFVdVdVFXA9cPHQmB1t+RbgvNm9FUnS4lmKcyTvTPLZdujrhFZbCzw+tM7uVlvblg+uP2dMVR0Avgq8fNQHJtmaZCbJzP79+xeuE0nSogfJNcArgDOBvcD7W33UnkTNU59vzKHFqmuralNVbVqzZs3zmrAkaX6LGiRV9URVPVtV3wQ+BJzT3toNnDq06jpgT6uvG1F/zpgkq4CXMf6hNEnSAlnUIGnnPGa9BZi9ous2YHO7Eut0BifVd1bVXuCpJOe28x+XALcOjdnSlt8KfKqdR5EkLaJVk9pwko8CrwdWJ9kNvBd4fZIzGRyCegz4ZYCqeiDJzcCDwAHgsqp6tm3qHQyuADsOuL09AK4Dbkiyi8GeyOZJ9SJJmtvEgqSq3j6ifN08628Hto+ozwCvHlH/OvC2njlKkvr5l+2SpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqctYQZLkkMtvJUmC8fdI/jjJziS/muQ7JjkhSdJ0GStIquqHgJ9jcG+rmSR/nuTHJzozSdJUGPscSVU9Avw28JvAjwJXJ/lckp+a1OQkScvfuOdIvi/JVcBDwI8Bb66q723LV01wfpKkZW7ce239IYPbvr+nqr42W6yqPUl+eyIzkyRNhXGD5ELga7N35E3yAuBFVfW/VXXDxGYnSVr2xj1H8vcMbuM+68WtJkla4cYNkhdV1X/PvmjLL57MlCRJ02TcIPmfJGfNvkhyNvC1edaXJK0Q454jeRfwsSSzv5d+CvCzE5mRJGmqjBUkVfWZJN8DfDcQ4HNV9Y2JzkySNBWez0/tvhZY38a8JglVdf1EZiVJmhpjBUmSG4BXAPcCz7ZyAQaJJK1w4+6RbAI2VlVNcjKSpOkz7lVb9wPfOcmJSJKm07h7JKuBB5PsBJ6eLVbVT05kVpKkqTFukFwxyUlIkqbXuJf//mOS7wI2VNXfJ3kxcMxkpyZJmgbj3kb+l4BbgD9ppbXAJyc0J0nSFBn3ZPtlwOuAJ+FbP3J10qQmJUmaHuMGydNV9czsiySrGPwdiSRphRs3SP4xyXuA49pvtX8M+MvJTUuSNC3GDZJtwH7gPuCXgb9m8PvtkqQVbtyrtr7J4Kd2PzTZ6UiSps2499p6lBHnRKrqjAWfkSRpqjyfe23NehHwNuDEhZ+OJGnajHWOpKr+a+jxxar6feDHJjs1SdI0GPfQ1llDL1/AYA/lpROZkSRpqox7aOv9Q8sHgMeAn1nw2UiSps64V229YdITkSRNp3EPbf36fO9X1QcWZjqSpGnzfK7aei1wW3v9ZuDTwOOTmJQkaXqM+5ftq4GzqurdVfVu4GxgXVX9blX97qgBST6cZF+S+4dqJya5I8kj7fmEofcuT7IrycNJzh+qn53kvvbe1UnS6scmuanV706y/gj6lyR1GjdITgOeGXr9DLD+MGM+AlxwUG0bcGdVbQDubK9JshHYDLyqjflgktnfO7kG2ApsaI/ZbV4KfKWqXglcBVw5Zi+SpAU0bpDcAOxMckWS9wJ3A9fPN6CqPg18+aDyRcCOtrwDuHiofmNVPV1VjwK7gHOSnAIcX1V3VVW1z7x4xLZuAc6b3VuRJC2eca/a2p7kduCHW+kXqupfj+DzTq6qvW2be5PM/qbJWuCfh9bb3WrfaMsH12fHPN62dSDJV4GXA186+EOTbGWwV8Npp512BNOWJM1l3D0SgBcDT1bVHwC7k5y+gPMYtSdR89TnG3NoseraqtpUVZvWrFlzhFOUJI0y7k/tvhf4TeDyVnoh8KdH8HlPtMNVtOd9rb4bOHVovXXAnlZfN6L+nDHth7ZexqGH0iRJEzbuHslbgJ8E/gegqvZwZLdIuQ3Y0pa3ALcO1Te3K7FOZ3BSfWc7DPZUknPb+Y9LDhozu623Ap9q51EkSYto3L8jeaaqKkkBJHnJ4QYk+SjwemB1kt3Ae4H3ATcnuRT4AoO7CFNVDyS5GXiQwS1YLquqZ9um3sHgCrDjgNvbA+A64IYkuxjsiWwesxdJ0gIaN0huTvInwHck+SXgFznMj1xV1dvneOu8OdbfDmwfUZ8BXj2i/nVaEEmSls5hg6QdUroJ+B7gSeC7gd+pqjsmPDdJ0hQ4bJC0Q1qfrKqzAcNDkvQc455s/+ckr53oTCRJU2nccyRvAH4lyWMMrtwKg52V75vUxCRJ02HeIElyWlV9AXjjIs1HkjRlDrdH8kkGd/39zyQfr6qfXoQ5SZKmyOHOkQzfhuSMSU5EkjSdDhckNceyJEnA4Q9tfX+SJxnsmRzXluH/T7YfP9HZSZKWvXmDpKqOme99SZKez23kJUk6hEEiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6GCSSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqcuSBEmSx5Lcl+TeJDOtdmKSO5I80p5PGFr/8iS7kjyc5Pyh+tltO7uSXJ0kS9GPJK1kS7lH8oaqOrOqNrXX24A7q2oDcGd7TZKNwGbgVcAFwAeTHNPGXANsBTa0xwWLOH9JEsvr0NZFwI62vAO4eKh+Y1U9XVWPAruAc5KcAhxfVXdVVQHXD42RJC2SpQqSAv4uyT1JtrbayVW1F6A9n9Tqa4HHh8bubrW1bfng+iGSbE0yk2Rm//79C9iGJGnVEn3u66pqT5KTgDuSfG6edUed96h56ocWq64FrgXYtGnTyHUkSUdmSfZIqmpPe94HfAI4B3iiHa6iPe9rq+8GTh0avg7Y0+rrRtQlSYto0YMkyUuSvHR2GfgJ4H7gNmBLW20LcGtbvg3YnOTYJKczOKm+sx3+eirJue1qrUuGxkiSFslSHNo6GfhEu1J3FfDnVfU3ST4D3JzkUuALwNsAquqBJDcDDwIHgMuq6tm2rXcAHwGOA25vD0nSIlr0IKmq/wC+f0T9v4Dz5hizHdg+oj4DvHqh5yhJGt9yuvxXkjSFDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUZeqDJMkFSR5OsivJtqWejyStNFMdJEmOAf4IeCOwEXh7ko1LOytJWllWLfUEOp0D7Kqq/wBIciNwEfDgks5qDuu3/dURj33sfW9awJlI0sKZ9iBZCzw+9Ho38AMHr5RkK7C1vfzvJA8f4eetBr50hGO75MpF/8gl63WR2efRZ6X0uth9ftdcb0x7kGRErQ4pVF0LXNv9YclMVW3q3c40WCm92ufRZ6X0upz6nOpzJAz2QE4der0O2LNEc5GkFWnag+QzwIYkpyf5NmAzcNsSz0mSVpSpPrRVVQeSvBP4W+AY4MNV9cAEP7L78NgUWSm92ufRZ6X0umz6TNUhpxQkSRrbtB/akiQtMYNEktTFIBnT0XArliSPJbkvyb1JZlrtxCR3JHmkPZ8wtP7lrd+Hk5w/VD+7bWdXkquTjLoMe9Ek+XCSfUnuH6otWF9Jjk1yU6vfnWT9ojb4//Mb1ecVSb7YvtN7k1w49N609nlqkn9I8lCSB5L8Wqsfjd/pXL1O1/daVT4O82BwIv/zwBnAtwH/Bmxc6nkdQR+PAasPqv0esK0tbwOubMsbW5/HAqe3/o9p7+0EfpDB3/HcDrxxifv6EeAs4P5J9AX8KvDHbXkzcNMy6vMK4DdGrDvNfZ4CnNWWXwr8e+vnaPxO5+p1qr5X90jG861bsVTVM8DsrViOBhcBO9ryDuDiofqNVfV0VT0K7ALOSXIKcHxV3VWDf5nXD41ZElX1aeDLB5UXsq/hbd0CnLcUe2Fz9DmXae5zb1X9S1t+CniIwV0sjsbvdK5e57IsezVIxjPqVizzfdnLVQF/l+SeDG4bA3ByVe2FwT9q4KRWn6vntW354Ppys5B9fWtMVR0Avgq8fGIzf/7emeSz7dDX7OGeo6LPdhjmNcDdHOXf6UG9whR9rwbJeMa6FcsUeF1VncXgbsmXJfmRedadq+dp/9/iSPpazj1fA7wCOBPYC7y/1ae+zyTfDnwceFdVPTnfqiNq097rVH2vBsl4jopbsVTVnva8D/gEg0N2T7TdYtrzvrb6XD3vbssH15ebhezrW2OSrAJexviHmCaqqp6oqmer6pvAhxh8pzDlfSZ5IYP/sP5ZVf1FKx+V3+moXqftezVIxjP1t2JJ8pIkL51dBn4CuJ9BH1vaaluAW9vybcDmdsXH6cAGYGc7pPBUknPbcdZLhsYsJwvZ1/C23gp8qh2HXnKz/2Ft3sLgO4Up7rPN6zrgoar6wNBbR913OlevU/e9LuYVCtP8AC5kcEXF54HfWur5HMH8z2Bwtce/AQ/M9sDgWOmdwCPt+cShMb/V+n2YoSuzgE3tH/bngT+k3SFhCXv7KIPd/28w+H9fly5kX8CLgI8xOLG5EzhjGfV5A3Af8FkG/8E45Sjo84cYHHr5LHBve1x4lH6nc/U6Vd+rt0iRJHXx0JYkqYtBIknqYpBIkroYJJKkLgaJJKmLQSJJ6mKQSJK6/B8QS/adfJ1O5AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = df_clean['line'].str.split(expand=True)\n",
    "word_counts = words.stack().value_counts()\n",
    "word_counts.plot.hist(bins=20)\n",
    "# log-log scale (power law)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Talkativity\n",
    "**Q5**. For each of the recurrent characters, calculate their total number of words uttered across all episodes. Based on this, who seems to be the most talkative character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/_7nfqv556wvd8gm4wp6z338h0000gn/T/ipykernel_9760/4003793688.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_most_speak['word_count'] = df_most_speak['line'].str.split().apply(len)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "character\n",
       "Sheldon         174911\n",
       "Leonard          95608\n",
       "Penny            74247\n",
       "Howard           64988\n",
       "Raj              56390\n",
       "Amy              37384\n",
       "Bernadette       25810\n",
       "Stuart            7407\n",
       "Mrs Cooper        3205\n",
       "Beverley          1918\n",
       "Priya             1824\n",
       "Wil               1577\n",
       "Emily             1472\n",
       "Mrs Wolowitz      1364\n",
       "Arthur            1353\n",
       "Zack              1336\n",
       "Leslie            1164\n",
       "Kripke            1163\n",
       "Bert              1065\n",
       "Name: word_count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_most_speak = df[df['character'].isin(recurrent_characters)]\n",
    "df_most_speak['word_count'] = df_most_speak['line'].str.split().apply(len)\n",
    "df_most_speak.groupby('character')['word_count'].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task D: The Detective's Hat\n",
    "\n",
    "Sheldon claims that given a dialogue line, he can, with an accuracy of above 70%, say whether it's by himself or by someone else. Leonard contests this claim, since he believes that this claimed accuracy is too high. Leonard also suspects that it's easier for Sheldon to distinguish the lines that _aren't_ his, rather than those that _are_. We want you to put on the (proverbial) detective's hat and to investigate this claim.\n",
    "\n",
    "**Q6**. Divide the set of all dialogue lines into two subsets: the training set, consisting of all the seasons except the last two, and the test set, consisting of the last two seasons. Each of your data points (which is one row of your matrix) is one **dialogue line**. Now, use the scikit-learn class **TfIdfVectorizer** to create TF-IDF representations for the data points in your training and test sets. Note that since you're going to train a machine learning model, everything used in the training needs to be independent of the test set. As a preprocessing step, remove stopwords and words that appear only once from your vocabulary. Use the simple tokenizer provided in `helpers/helper_functions.py` as an input to the TfidfVectorizer class, and use the words provided in `helpers/stopwords.txt` as your stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_season = df_clean.copy()\n",
    "df_season['season'] = df['episode'].str.split()\n",
    "df_season['season'] = df_season['season'].apply(lambda x: int(x[1]))\n",
    "df_train = df_season[df_season['season'] <= 8]\n",
    "df_test = df_season[df_season['season'] > 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'm',\n",
       " 're',\n",
       " 'uh',\n",
       " 'oh',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " 'should',\n",
       " 'now',\n",
       " 'okay',\n",
       " 'ok',\n",
       " 'yes',\n",
       " 'yeah',\n",
       " 'yep',\n",
       " 'yup',\n",
       " 'no',\n",
       " 'nope',\n",
       " 'nah']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('helpers/stopwords.txt', 'r') as f:\n",
    "    stopwords = [a.replace('\\n', '') for a in f.readlines()]\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wocket',\n",
       " 'slower',\n",
       " 'itching',\n",
       " 'bwagging',\n",
       " 'provisional',\n",
       " 'remarried',\n",
       " 'twenties',\n",
       " 'plopped',\n",
       " 'complimenting',\n",
       " 'diss',\n",
       " 'wucky',\n",
       " 'rot',\n",
       " 'enthusiasm',\n",
       " 'leaked',\n",
       " 'crisp',\n",
       " 'kringle',\n",
       " 'flatworms',\n",
       " 'workable',\n",
       " 'airflow',\n",
       " 'facilitate',\n",
       " 'ticks',\n",
       " 'issue…',\n",
       " 'conically',\n",
       " 'flashing',\n",
       " 'shnerpf',\n",
       " 'uncharted',\n",
       " 'adhering',\n",
       " 'electronics',\n",
       " 'thorne',\n",
       " 'perpetuate',\n",
       " 'commies',\n",
       " 'invoked',\n",
       " 'jaywalked',\n",
       " 'camped',\n",
       " 'deployability',\n",
       " 'maniac',\n",
       " 'mated',\n",
       " 'overcrowding',\n",
       " 'doted',\n",
       " 'specialized',\n",
       " 'dawning',\n",
       " 'soufflé',\n",
       " 'snitch',\n",
       " 'jaywalk',\n",
       " 'cad',\n",
       " 'chocula',\n",
       " 'bernardino',\n",
       " 'racking',\n",
       " 'prototypes',\n",
       " 'applicator',\n",
       " 'trix',\n",
       " 'restricting',\n",
       " 'samantha',\n",
       " 'reintroduce',\n",
       " 'wheeler',\n",
       " 'tools…',\n",
       " 'pinholes',\n",
       " 'kip',\n",
       " 'laughable',\n",
       " 'defense…',\n",
       " 'bwiwiant',\n",
       " 'consoling',\n",
       " 'buckew',\n",
       " 'revert',\n",
       " 'headlights',\n",
       " 'neanderthals',\n",
       " 'abusing',\n",
       " 'creeds',\n",
       " 'galvanized',\n",
       " 'cryostat',\n",
       " 'excuses',\n",
       " 'denigrated',\n",
       " 'cob',\n",
       " 'lumber',\n",
       " 'emasculating',\n",
       " 'recollections',\n",
       " 'modeling',\n",
       " 'toothbrushes',\n",
       " 'turnabout',\n",
       " 'duke',\n",
       " 'fweak',\n",
       " 'copper',\n",
       " 'sapiens',\n",
       " 'cutsies',\n",
       " 'jenofski',\n",
       " 'agnostic',\n",
       " '295118',\n",
       " 'zimmerman',\n",
       " 'wingewie',\n",
       " 'wrongdoing',\n",
       " 'unload',\n",
       " 'unprofessional',\n",
       " 'hyphen',\n",
       " 'fibonacci',\n",
       " 'alina',\n",
       " 'dissect',\n",
       " 'shankar',\n",
       " 'embassy',\n",
       " 'presto',\n",
       " 'bronzed',\n",
       " '914',\n",
       " 'ops',\n",
       " '03',\n",
       " 'unthinkable',\n",
       " 'crops',\n",
       " 'frost…',\n",
       " 'biodome',\n",
       " 'wevew',\n",
       " 'enclosed',\n",
       " 'sewage',\n",
       " 'peasant',\n",
       " 'yonder',\n",
       " 'elaine',\n",
       " 'atheist',\n",
       " 'blobert',\n",
       " 'graded',\n",
       " 'dissected',\n",
       " 'etch',\n",
       " 'pokemon',\n",
       " 'reprinting',\n",
       " 'streetcar',\n",
       " 'pipes',\n",
       " 'wunch',\n",
       " 'pete',\n",
       " 'poolside',\n",
       " 'coital',\n",
       " 'yuletide',\n",
       " 'tardy',\n",
       " 'purport',\n",
       " 'gameboy',\n",
       " 'sketch',\n",
       " 'earnest',\n",
       " 'rising',\n",
       " 'tinsel',\n",
       " 'perverts',\n",
       " 'put…',\n",
       " 'amys',\n",
       " 'kickstand',\n",
       " 'psp',\n",
       " 'blobbi',\n",
       " 'bloberta',\n",
       " 'christmases',\n",
       " 'disrespects',\n",
       " 'ds',\n",
       " 'bureaucratic',\n",
       " 'acquisitions',\n",
       " 'temptation',\n",
       " 'paralysis',\n",
       " 'unchain',\n",
       " 'goofus',\n",
       " 'radiates',\n",
       " 'pediatric',\n",
       " 'smoothed',\n",
       " 'iguanas',\n",
       " 'suffew',\n",
       " 'calculators',\n",
       " 'swapsies',\n",
       " '…when',\n",
       " 'blinding',\n",
       " 'unlucky',\n",
       " 'edgewise',\n",
       " 'williamsburg',\n",
       " 'waid',\n",
       " 'shindig',\n",
       " 'nick',\n",
       " 'revolution',\n",
       " 'rein',\n",
       " 'unexpressed',\n",
       " 'mobility',\n",
       " 'corrosion',\n",
       " 'unerring',\n",
       " 'baybrook',\n",
       " 'rigour',\n",
       " 'indigo',\n",
       " 'forgiveness…',\n",
       " 'devotion',\n",
       " 'outhouse',\n",
       " 'unshaven',\n",
       " 'pine',\n",
       " 'simulating',\n",
       " 'puck',\n",
       " 'squishing',\n",
       " 'snuggling',\n",
       " 'sweatshops',\n",
       " 'admission',\n",
       " 'compatibility',\n",
       " 'apprehension',\n",
       " 'reclaiming',\n",
       " 'kiwing',\n",
       " 'grouch',\n",
       " 'breakthroughs',\n",
       " 'girlfwiend',\n",
       " 'mosquitoes',\n",
       " 'ions',\n",
       " 'diagnosable',\n",
       " 'pway',\n",
       " 'renounce',\n",
       " 'monk',\n",
       " 'bloodied',\n",
       " 'angioplasty',\n",
       " 'accommodations',\n",
       " 'lactation',\n",
       " 'jostling',\n",
       " 'consultants',\n",
       " 'blob',\n",
       " 'fables',\n",
       " 'crackle',\n",
       " 'borrowing',\n",
       " 'rediscovered',\n",
       " 'darnedest',\n",
       " 'presumed',\n",
       " 'declares',\n",
       " 'poached',\n",
       " 'officiate',\n",
       " 'accelerators',\n",
       " 'commencing',\n",
       " 'nasal',\n",
       " 'navigational',\n",
       " 'syllables',\n",
       " 'extinction',\n",
       " 'fireman',\n",
       " 'rumpled',\n",
       " 'lunges',\n",
       " 'brioche',\n",
       " 'olds',\n",
       " 'fermilab',\n",
       " 'stranded',\n",
       " 'chillies',\n",
       " 'brisk',\n",
       " 'harassing',\n",
       " 'cogs',\n",
       " 'mxyzptlk',\n",
       " 'payday',\n",
       " 'unborn',\n",
       " 'parched',\n",
       " 'oobius',\n",
       " 'depressus',\n",
       " 'processed',\n",
       " 'commercially',\n",
       " 'coldest',\n",
       " 'concur',\n",
       " 'danny',\n",
       " 'creed',\n",
       " 'fulfillment',\n",
       " 'gasp',\n",
       " 'gyroscopic',\n",
       " 'parasitoid',\n",
       " 'mandated',\n",
       " 'zing',\n",
       " 'geriatric',\n",
       " 'moxie',\n",
       " 'groupies',\n",
       " 'santiago',\n",
       " 'plod',\n",
       " 'stooge',\n",
       " 'cajal',\n",
       " 'expander',\n",
       " 'sincerest',\n",
       " 'metabolic',\n",
       " 'stop…',\n",
       " 'salespeople',\n",
       " 'whipping',\n",
       " 'hammers',\n",
       " 'ginny',\n",
       " 'intrinsic',\n",
       " 'noir',\n",
       " 'gravitas',\n",
       " 'illustrates',\n",
       " 'elder',\n",
       " 'farming',\n",
       " 'jackpot',\n",
       " 'retinal',\n",
       " 'thermo',\n",
       " 'doormat',\n",
       " 'canterbury',\n",
       " 'unforgiving',\n",
       " 'ace',\n",
       " 'vats',\n",
       " 'expectant',\n",
       " 'fortitude',\n",
       " 'change…',\n",
       " 'maps',\n",
       " 'aching',\n",
       " 'catalogue',\n",
       " 'biffle',\n",
       " 'stressing',\n",
       " 'alvin',\n",
       " 'oppresses',\n",
       " 'retrovirus',\n",
       " 'lightin',\n",
       " 'wielding',\n",
       " 'gyroscopes',\n",
       " 'chewable',\n",
       " 'rhythmically',\n",
       " 'lasted',\n",
       " 'contributing',\n",
       " 'abhorrent',\n",
       " 'wrecker',\n",
       " 'unsigned',\n",
       " 'darker',\n",
       " 'possessive',\n",
       " 'trebek',\n",
       " 'afrin',\n",
       " 'confronted',\n",
       " 'chaotic',\n",
       " 'indefinitely',\n",
       " 'stubble',\n",
       " 'immunotherapy',\n",
       " 'besserwisser',\n",
       " '160th',\n",
       " 'assistantone',\n",
       " 'rockford',\n",
       " 'arguments',\n",
       " 'objectify',\n",
       " 'tucking',\n",
       " 'evidenced',\n",
       " 'over…',\n",
       " 'slid',\n",
       " 'punisher',\n",
       " '220',\n",
       " 'sculptor',\n",
       " 'scamp',\n",
       " 'hangover',\n",
       " 'ingested',\n",
       " 'melba',\n",
       " 'uncivilized',\n",
       " 'busboys',\n",
       " 'outgoing',\n",
       " 'jingles',\n",
       " 'assures',\n",
       " 'motorists',\n",
       " 'digit',\n",
       " 'competence',\n",
       " 'perpetually',\n",
       " 'tatellah',\n",
       " 'mumbles',\n",
       " 'bypasses',\n",
       " 'anthrax',\n",
       " 'harem',\n",
       " 'blaming',\n",
       " 'tilefish',\n",
       " 'lori',\n",
       " 'brakkadoom',\n",
       " 'mackerel',\n",
       " 'soleil',\n",
       " 'cirque',\n",
       " 'rumble',\n",
       " 'enrages',\n",
       " 'drano',\n",
       " 'cultivate',\n",
       " 'manga…',\n",
       " 'civilians',\n",
       " 'accusations',\n",
       " 'dimmed',\n",
       " 'forgave',\n",
       " 'intestate',\n",
       " 'vazquez',\n",
       " 'recalculating',\n",
       " 'chugging',\n",
       " 'oontz…',\n",
       " 'sanders',\n",
       " 'wails',\n",
       " 'enraged',\n",
       " 'acrobats',\n",
       " 'disguised',\n",
       " 'thematically',\n",
       " 'nighty',\n",
       " 'planet”',\n",
       " 'withdrawal',\n",
       " 'aficionado',\n",
       " '87th',\n",
       " 'doubled',\n",
       " 'deleted',\n",
       " 'homicide',\n",
       " 'chromic',\n",
       " 'immigration',\n",
       " 'bloopers',\n",
       " 'trend',\n",
       " 'firmly',\n",
       " 'honked',\n",
       " 'setter',\n",
       " 'susan',\n",
       " 'afghan',\n",
       " 'paired',\n",
       " 'dependency',\n",
       " 'rebrand',\n",
       " 'angrier',\n",
       " 'ventimiglia',\n",
       " 'shoebox',\n",
       " 'beeting',\n",
       " 'worrisome',\n",
       " 'rarified',\n",
       " 'strutting',\n",
       " 'snipes',\n",
       " 'taped',\n",
       " 'suckah',\n",
       " 'mingle',\n",
       " 'bo',\n",
       " 'della',\n",
       " 'buster',\n",
       " 'theon',\n",
       " 'flirtations',\n",
       " 'kellogg',\n",
       " 'sumo',\n",
       " 'overstepped',\n",
       " 'crystal',\n",
       " 'construed',\n",
       " 'dawg',\n",
       " 'mimicking',\n",
       " 'stepbrothers',\n",
       " 'suppository',\n",
       " 'ripe',\n",
       " 'battled',\n",
       " 'pouty',\n",
       " 'fuwious',\n",
       " 'dinty',\n",
       " 'unkempt',\n",
       " 'rectum…',\n",
       " 'glide',\n",
       " 'contributed',\n",
       " 'moore',\n",
       " 'cheerio',\n",
       " 'franken',\n",
       " 'westin',\n",
       " 'compounds',\n",
       " 'boosting',\n",
       " 'thelma',\n",
       " 'zingers',\n",
       " 'agweed',\n",
       " 'offender',\n",
       " 'bumpkin',\n",
       " 'nurseries',\n",
       " 'instincts',\n",
       " 'dubbed',\n",
       " 'twuck',\n",
       " 'rigid',\n",
       " 'symmetries',\n",
       " 'apps',\n",
       " 'babysit',\n",
       " 'wigs',\n",
       " 'chipmunks',\n",
       " 'rotational',\n",
       " 'dobby',\n",
       " 'thumping',\n",
       " 'fana',\n",
       " 'feeting',\n",
       " 'wedged',\n",
       " 'ymca',\n",
       " 'tyrant',\n",
       " 'classically',\n",
       " 'truffles',\n",
       " 'sideways',\n",
       " 'stds',\n",
       " 'glances',\n",
       " 'defense',\n",
       " 'contact…',\n",
       " 'vaporize',\n",
       " 'glaringly',\n",
       " 'capitols',\n",
       " 'hofstadter…',\n",
       " 'enhancing',\n",
       " 'aol',\n",
       " 'desirability',\n",
       " 'persecuted',\n",
       " 'contemplation',\n",
       " 'skyrocketing',\n",
       " 'awowed',\n",
       " 'transitive',\n",
       " 'weightless',\n",
       " 'joints',\n",
       " 'joffrey',\n",
       " 'wrinkly',\n",
       " 'fornicating',\n",
       " 'elope',\n",
       " 'menstruating',\n",
       " 'oblivion',\n",
       " 'montage',\n",
       " 'pistachio',\n",
       " 'feminist',\n",
       " 'investigate',\n",
       " 'hostile',\n",
       " 'burt',\n",
       " 'morta',\n",
       " 'trimester',\n",
       " 'yards',\n",
       " 'jumbotron',\n",
       " 'poltergeist',\n",
       " 'illustrated',\n",
       " 'kardashian',\n",
       " 'brann',\n",
       " 'kourtney',\n",
       " 'maroon',\n",
       " 'chattahoochee',\n",
       " 'shipped',\n",
       " 'oozy',\n",
       " 'leafing',\n",
       " 'suckling',\n",
       " 'subcommittee',\n",
       " 'plight',\n",
       " 'meetings',\n",
       " 'unsympathetic',\n",
       " 'orphanage',\n",
       " 'vendor',\n",
       " 'criticizes',\n",
       " 'bouncer',\n",
       " 'antagonizes',\n",
       " 'overdid',\n",
       " 'plugging',\n",
       " 'andrews',\n",
       " 'cycle…',\n",
       " 'singling',\n",
       " 'cruises',\n",
       " 'elliott',\n",
       " 'accusing',\n",
       " 'sculpt',\n",
       " 'hints',\n",
       " 'blab',\n",
       " 'personalised',\n",
       " 'homeboy',\n",
       " 'defining',\n",
       " 'hebraic',\n",
       " 'objected',\n",
       " 'irritability',\n",
       " 'predicts',\n",
       " 'poker',\n",
       " 'squashed',\n",
       " 'nanometer',\n",
       " 'adho',\n",
       " 'mukha',\n",
       " 'shvanasana',\n",
       " 'sassy',\n",
       " 'scrub',\n",
       " 'hoped',\n",
       " 'redact',\n",
       " 'honking',\n",
       " 'redacting',\n",
       " 'spendy',\n",
       " 'honk',\n",
       " 'pinpoint',\n",
       " 'resides',\n",
       " 'infinity',\n",
       " 'attosecond',\n",
       " 'hippy',\n",
       " 'funds',\n",
       " 'glistening',\n",
       " 'tanned',\n",
       " 'rio',\n",
       " 'connects',\n",
       " 'tini',\n",
       " 'sevenths',\n",
       " 'weaker',\n",
       " 'collaborated',\n",
       " 'groveller',\n",
       " 'grovel',\n",
       " 'moisturizing',\n",
       " 'definite',\n",
       " 'disagreements',\n",
       " 'yuh',\n",
       " 'guzzle',\n",
       " 'successes',\n",
       " 'needlepoint',\n",
       " 'locust',\n",
       " 'citing',\n",
       " 'gelatinous',\n",
       " 'screamed',\n",
       " 'hubby',\n",
       " 'sources',\n",
       " 'prattles',\n",
       " 'hula',\n",
       " 'defensiveness',\n",
       " 'defensively',\n",
       " 'realities',\n",
       " 'charade',\n",
       " 'discounts',\n",
       " 'carpentry',\n",
       " 'transform',\n",
       " 'brew',\n",
       " 'shrinking',\n",
       " 'unfairly',\n",
       " 'buildup',\n",
       " 'wedded',\n",
       " 'raisinet',\n",
       " 'unconsciously',\n",
       " 'hammerhead',\n",
       " 'bromance',\n",
       " 'contingency',\n",
       " 'influence',\n",
       " 'sponging',\n",
       " 'rib',\n",
       " 'satan',\n",
       " 'killin',\n",
       " 'politely',\n",
       " 'girly',\n",
       " 'fiesta',\n",
       " 'reacts',\n",
       " 'perception',\n",
       " 'reconfirmed',\n",
       " 'convey',\n",
       " 'peering',\n",
       " 'hydration',\n",
       " 'uncomprehending',\n",
       " 'backpacks',\n",
       " 'unfolding',\n",
       " 'majesty',\n",
       " 'zeusowitz',\n",
       " 'council…',\n",
       " 'lentil',\n",
       " 'pros',\n",
       " 'cooled',\n",
       " 'ghajtah',\n",
       " 'pedigree',\n",
       " 'tlhej',\n",
       " 'yin',\n",
       " 'brb',\n",
       " 'corpus',\n",
       " 'callosum',\n",
       " 'tah',\n",
       " 'slurp',\n",
       " 'tu',\n",
       " 'spork',\n",
       " 'vera',\n",
       " 'aloe',\n",
       " 'utensil',\n",
       " 'reverend',\n",
       " 'ministers',\n",
       " 'mamas',\n",
       " 'twins…',\n",
       " 'inelegant',\n",
       " 'grammy',\n",
       " 'fakakta',\n",
       " 'camptown',\n",
       " 'sliders',\n",
       " 'occipital',\n",
       " 'bleached',\n",
       " 'milliseconds',\n",
       " 'swirl',\n",
       " 'flavours',\n",
       " 'tannins',\n",
       " 'specified',\n",
       " 'textures',\n",
       " 'contractual',\n",
       " 'daring',\n",
       " 'sharpening',\n",
       " 'collaborating',\n",
       " 'disinterested',\n",
       " 'bonehead',\n",
       " 'numerous',\n",
       " 'stated',\n",
       " 'sharpest',\n",
       " 'guppies',\n",
       " 'sandal',\n",
       " 'eloquently',\n",
       " 'arise',\n",
       " 'dismiss',\n",
       " 'feel…',\n",
       " 'onlooker',\n",
       " 'truthful…',\n",
       " 'listener',\n",
       " 'olsen',\n",
       " 'stickler',\n",
       " 'dosage',\n",
       " 'occupants',\n",
       " 'modem',\n",
       " 'smoothness',\n",
       " 'haolam',\n",
       " 'concavity',\n",
       " 'melech',\n",
       " 'slouch',\n",
       " 'eloheinu',\n",
       " 'adonai',\n",
       " 'divers',\n",
       " 'atah',\n",
       " 'baruch',\n",
       " 'cheaply',\n",
       " 'slowing',\n",
       " 'exhale',\n",
       " 'arranging',\n",
       " 'equilateral',\n",
       " 'lechem',\n",
       " 'nostalgic',\n",
       " 'reunited',\n",
       " 'triangles',\n",
       " 'hysteresis',\n",
       " 'ferromagnetic',\n",
       " 'electromagnetism””',\n",
       " 'rederivation',\n",
       " 'unearthed',\n",
       " 'grover',\n",
       " 'scalene',\n",
       " 'thrilla',\n",
       " 'boxing',\n",
       " 'gucci',\n",
       " 'velvet',\n",
       " 'hamotzi',\n",
       " 'min',\n",
       " 'roofing',\n",
       " '401k',\n",
       " 'defrost',\n",
       " 'batch',\n",
       " 'loseroneous',\n",
       " 'symbol',\n",
       " 'selfie',\n",
       " 'appease',\n",
       " 'horas',\n",
       " 'operación',\n",
       " 'naturalized',\n",
       " 'recapture',\n",
       " 'copernicus',\n",
       " 'nicolaus',\n",
       " 'preschools',\n",
       " 'liverwurst',\n",
       " 'lactate',\n",
       " 'haaretz',\n",
       " 'manifold',\n",
       " 'unidentified',\n",
       " 'bratwurst',\n",
       " 'cdm',\n",
       " 'rebuttal',\n",
       " 'partons',\n",
       " 'vectors',\n",
       " 'blockheads',\n",
       " 'crankshaft',\n",
       " 'disadvantage',\n",
       " 'turbo',\n",
       " 'demonstrates',\n",
       " 'mandel',\n",
       " 'kinetic',\n",
       " 'msn',\n",
       " 'altavista',\n",
       " 'mandrill',\n",
       " 'assess',\n",
       " 'che',\n",
       " 'sidewalk',\n",
       " 'unimpaired',\n",
       " 'reports',\n",
       " 'mainstream',\n",
       " 'demographic',\n",
       " 'mystique',\n",
       " 'comprehensive',\n",
       " 'iowa',\n",
       " 'concealer',\n",
       " 'irs',\n",
       " 'handouts',\n",
       " 'rafting',\n",
       " 'abelion',\n",
       " 'erogenous',\n",
       " 'courting',\n",
       " 'combing',\n",
       " 'stride',\n",
       " 'panelists',\n",
       " 'tramping',\n",
       " 'cot',\n",
       " 'promoter',\n",
       " '1964',\n",
       " 'heater',\n",
       " 'spruce',\n",
       " 'occupant',\n",
       " 'astronautie',\n",
       " 'hangdog',\n",
       " '50th',\n",
       " 'hygienist',\n",
       " 'exhibits',\n",
       " 'ese',\n",
       " 'vendors',\n",
       " 'dr…',\n",
       " 'jeeves',\n",
       " 'defunct',\n",
       " 'froggy',\n",
       " 'automatically',\n",
       " 'unlocked',\n",
       " 'infoseek',\n",
       " 'webcrawler',\n",
       " 'sanity',\n",
       " 'hotbot',\n",
       " 'asteroids',\n",
       " 'trojan',\n",
       " 'soot',\n",
       " 'glimpse',\n",
       " 'cruelly',\n",
       " 'gossiping',\n",
       " 'salary',\n",
       " 'schlepped',\n",
       " 'swirled',\n",
       " 'imported',\n",
       " 'lashes',\n",
       " 'redness',\n",
       " 'curler',\n",
       " 'chauffeured',\n",
       " 'eyelash',\n",
       " 'vigorous',\n",
       " 'suspenders',\n",
       " 'accounting',\n",
       " 'sponsor',\n",
       " 'ewoks',\n",
       " 'wrinkle',\n",
       " 'platypus',\n",
       " '1965',\n",
       " 'awwive',\n",
       " 'listings',\n",
       " 'practices',\n",
       " 'drums',\n",
       " 'erasing',\n",
       " 'labeled',\n",
       " 'confiscated',\n",
       " 'exceeding',\n",
       " 'avail',\n",
       " 'cognition',\n",
       " 'antihistamines',\n",
       " 'radiant',\n",
       " 'meals',\n",
       " 'dowwaws',\n",
       " 'hundwed',\n",
       " 'mammogram',\n",
       " 'consummating',\n",
       " 'stwippers',\n",
       " 'fewwow',\n",
       " 'jowwy',\n",
       " 'fellow…',\n",
       " 'valet',\n",
       " 'structures',\n",
       " 'harmonica',\n",
       " 'bombs',\n",
       " 'amy…',\n",
       " 'stag',\n",
       " 'whisky',\n",
       " 'clingy',\n",
       " 'undertow',\n",
       " 'antifungal',\n",
       " 'pivoting',\n",
       " 'disconcerting',\n",
       " 'stwings',\n",
       " 'splinters',\n",
       " 'pasties',\n",
       " 'weast',\n",
       " 'compwetewy',\n",
       " 'stwippews',\n",
       " 'hobbies',\n",
       " 'impwication',\n",
       " 'closeted',\n",
       " 'bachewor',\n",
       " 'rumours',\n",
       " 'contestants',\n",
       " 'woud',\n",
       " 'couwage',\n",
       " 'evewybody',\n",
       " 'wwap',\n",
       " 'aquasocks',\n",
       " 'we…',\n",
       " 'knot',\n",
       " 'à',\n",
       " 'doubleazinga',\n",
       " 'hacha',\n",
       " 'unappealing',\n",
       " 'trois',\n",
       " 'poland',\n",
       " 'histories',\n",
       " 'snaps',\n",
       " 'bernadettemaryannrostenkowskiwolowitz',\n",
       " 'tallest',\n",
       " 'bendy',\n",
       " 'vitamin',\n",
       " 'hyphenate',\n",
       " 'interested…',\n",
       " 'hiring',\n",
       " 'vineyards',\n",
       " 'spleen',\n",
       " 'terrain',\n",
       " 'outings',\n",
       " 'torments',\n",
       " 'bango',\n",
       " 'smacking',\n",
       " 'tease',\n",
       " 'scrambling',\n",
       " '‘im',\n",
       " 'premium',\n",
       " 'slaps',\n",
       " 'hotay',\n",
       " 'quixote',\n",
       " 'lactaid',\n",
       " 'oddity',\n",
       " 'punishing',\n",
       " 'frenzied',\n",
       " 'gallbladder',\n",
       " 'trashy',\n",
       " 'cherie',\n",
       " 'guinness',\n",
       " 'skyped',\n",
       " 'petit',\n",
       " 'bead',\n",
       " 'corresponded',\n",
       " 'nickels',\n",
       " 'buffed',\n",
       " 'jewels',\n",
       " 'highlighted',\n",
       " 'hercules',\n",
       " 'bony',\n",
       " 'souvenirs',\n",
       " 'uneven',\n",
       " 'adaptability',\n",
       " 'delivers',\n",
       " 'sod',\n",
       " 'hughes',\n",
       " '9am',\n",
       " 'minefield',\n",
       " 'goldfinch',\n",
       " 'preposition',\n",
       " 'dunk',\n",
       " 'infinitive',\n",
       " 'adverb',\n",
       " 'kanga',\n",
       " 'admonish',\n",
       " 'vigorously',\n",
       " 'admonishing',\n",
       " 'arcadia',\n",
       " 'fungi',\n",
       " 'ibuprofen',\n",
       " 'tutorial',\n",
       " 'lured',\n",
       " 'scalar',\n",
       " 'fainter',\n",
       " 'boner',\n",
       " 'articulating',\n",
       " 'shrieking',\n",
       " 'sprained',\n",
       " 'dual',\n",
       " 'envelop',\n",
       " 'leveling',\n",
       " 'adjustment',\n",
       " 'gears',\n",
       " 'selfless',\n",
       " 'unweasonable',\n",
       " 'groomsman',\n",
       " 'cascading',\n",
       " 'lichtenstein',\n",
       " 'nations…',\n",
       " 'acknowledged',\n",
       " 'beatle',\n",
       " 'someones',\n",
       " 'seat…',\n",
       " 'sit…',\n",
       " 'excused',\n",
       " 'imitate',\n",
       " 'educators',\n",
       " 'vaccinations',\n",
       " 'fraction',\n",
       " 'rudely',\n",
       " 'coveted',\n",
       " 'cling',\n",
       " '288',\n",
       " 'morphed',\n",
       " 'sloths',\n",
       " 'orangutan',\n",
       " 'sighing',\n",
       " 'hope…',\n",
       " 'scientologist',\n",
       " 'deposits',\n",
       " 'revamped',\n",
       " '625',\n",
       " 'nutso',\n",
       " 'neighbourhoods',\n",
       " 'bismol',\n",
       " 'narrowly',\n",
       " 'sessions',\n",
       " '289',\n",
       " '290',\n",
       " 'hopper',\n",
       " '114',\n",
       " 'stimulated',\n",
       " 'minister',\n",
       " 'recreating',\n",
       " 'envision',\n",
       " 'tacky',\n",
       " 'lentils',\n",
       " 'tundra',\n",
       " 'tutor',\n",
       " 'burna…',\n",
       " 'clearer',\n",
       " 'recollect',\n",
       " 'skedaddle',\n",
       " 'weiches',\n",
       " 'warmes',\n",
       " 'processional',\n",
       " 'voiceover',\n",
       " 'nie',\n",
       " 'nimmer',\n",
       " '‘m',\n",
       " 'murrt',\n",
       " 'liebes',\n",
       " 'müdes',\n",
       " 'countdown',\n",
       " 'navajo',\n",
       " 'brides',\n",
       " 'economy',\n",
       " 'quivers',\n",
       " 'uniformity',\n",
       " 'calling…',\n",
       " 'maltodextrin',\n",
       " 'fallon',\n",
       " 'barging',\n",
       " 'grovelling',\n",
       " ...]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_once = df_clean['line'].str.split(expand=True).stack().value_counts()\n",
    "only_once = list(only_once[only_once == 1].index)\n",
    "only_once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/_7nfqv556wvd8gm4wp6z338h0000gn/T/ipykernel_9760/3417426632.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['line_preprocessed'] = df_train['line'].apply(lambda x: ' '.join([a for a in x.split() if a not in stopwords and a not in only_once]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>scene</th>\n",
       "      <th>character</th>\n",
       "      <th>line</th>\n",
       "      <th>season</th>\n",
       "      <th>line_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank._0</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>so if a photon is directed through a plane wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>photon directed plane two slits either slit ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank._0</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>agreed  what s your point</td>\n",
       "      <td>1</td>\n",
       "      <td>agreed point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank._0</td>\n",
       "      <td>Sheldon</td>\n",
       "      <td>there s no point  i just think it s a good id...</td>\n",
       "      <td>1</td>\n",
       "      <td>point think good idea tee shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank._0</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>excuse me</td>\n",
       "      <td>1</td>\n",
       "      <td>excuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>A corridor at a sperm bank._0</td>\n",
       "      <td>Receptionist</td>\n",
       "      <td>hang on</td>\n",
       "      <td>1</td>\n",
       "      <td>hang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 episode                           scene  \\\n",
       "0   Series 01 Episode 01 – Pilot Episode   A corridor at a sperm bank._0   \n",
       "1   Series 01 Episode 01 – Pilot Episode   A corridor at a sperm bank._0   \n",
       "2   Series 01 Episode 01 – Pilot Episode   A corridor at a sperm bank._0   \n",
       "3   Series 01 Episode 01 – Pilot Episode   A corridor at a sperm bank._0   \n",
       "4   Series 01 Episode 01 – Pilot Episode   A corridor at a sperm bank._0   \n",
       "\n",
       "      character                                               line  season  \\\n",
       "0       Sheldon   so if a photon is directed through a plane wi...       1   \n",
       "1       Leonard                         agreed  what s your point        1   \n",
       "2       Sheldon   there s no point  i just think it s a good id...       1   \n",
       "3       Leonard                                         excuse me        1   \n",
       "4  Receptionist                                           hang on        1   \n",
       "\n",
       "                                   line_preprocessed  \n",
       "0  photon directed plane two slits either slit ob...  \n",
       "1                                       agreed point  \n",
       "2                    point think good idea tee shirt  \n",
       "3                                             excuse  \n",
       "4                                               hang  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['line_preprocessed'] = df_train['line'].apply(lambda x: ' '.join([a for a in x.split() if a not in stopwords and a not in only_once]))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words=stopwords, min_df=2, tokenizer=simple_tokeniser)\n",
    "train_vect = vect.fit_transform(df_train['line'])\n",
    "test_vect = vect.transform(df_test['line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7**. Find the set of all words in the training set that are only uttered by Sheldon. Is it possible for Sheldon to identify himself only based on these? Use the test set to assess this possibility, and explain your method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sheldon = df_train[df_train['character'] == 'Sheldon']\n",
    "sheldon_words = set(df_sheldon['line'].str.split(expand=True).stack().value_counts().index)\n",
    "\n",
    "df_non_sheldon = df_train[df_train['character'] != 'Sheldon']\n",
    "non_sheldon_words = set(df_non_sheldon['line'].str.split(expand=True).stack().value_counts().index)\n",
    "\n",
    "unique_sheldon = sheldon_words - non_sheldon_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'semantically',\n",
       " 'exhaustion',\n",
       " 'interdepartmental',\n",
       " 'phosphorous',\n",
       " 'neutrons',\n",
       " 'universality',\n",
       " 'factoring',\n",
       " 'weltschmerz',\n",
       " 'clan',\n",
       " 'azure',\n",
       " 'influenza',\n",
       " 'satay',\n",
       " 'caption',\n",
       " 'baker',\n",
       " 'wha',\n",
       " 'neodymium',\n",
       " 'hungarians',\n",
       " 'absentmindedly',\n",
       " 'evidently',\n",
       " 'tangential',\n",
       " 'caress',\n",
       " 'newcomer',\n",
       " '640',\n",
       " 'unmitigated',\n",
       " 'retort',\n",
       " 'factions',\n",
       " 'tweeting',\n",
       " 'territories',\n",
       " 'aloe',\n",
       " 'overrated',\n",
       " 'mango',\n",
       " 'possession',\n",
       " 'colonizing',\n",
       " 'transformed',\n",
       " 'declined',\n",
       " 'cohort',\n",
       " 'pecking',\n",
       " 'unloading',\n",
       " 'ambient',\n",
       " 'irish',\n",
       " 'worf',\n",
       " 'lightsaber',\n",
       " 'inconsolable',\n",
       " 'regulation',\n",
       " 'acquaintances',\n",
       " 'creatures',\n",
       " 'auspicious',\n",
       " 'infernal',\n",
       " 'loomis',\n",
       " 'experts',\n",
       " 'playing…',\n",
       " 'thermodynamics',\n",
       " 'rarified',\n",
       " 'advised',\n",
       " 'frontier',\n",
       " 'select',\n",
       " 'conjugal',\n",
       " 'destruction',\n",
       " '67',\n",
       " 'generous',\n",
       " 'bowlers',\n",
       " 'codifies',\n",
       " 'cousteau',\n",
       " 'parakeet',\n",
       " 'overpower',\n",
       " 'noob',\n",
       " 'itsy',\n",
       " 'aligned',\n",
       " 'buggy',\n",
       " 'modesty',\n",
       " 'eliminated',\n",
       " 'fraternal',\n",
       " 'fandom',\n",
       " 'd…',\n",
       " 'concrete',\n",
       " 'stu…',\n",
       " 'tattling',\n",
       " 'screeches',\n",
       " 'contentious',\n",
       " 'use…',\n",
       " 'lessen',\n",
       " 'borne',\n",
       " 'nightshirt',\n",
       " 'smashes',\n",
       " 'bawwy',\n",
       " 'humankind',\n",
       " 'lowly',\n",
       " 'intellect',\n",
       " 'mockingbirds',\n",
       " 'befallen',\n",
       " 'toolbox',\n",
       " 'irritable',\n",
       " 'disproves',\n",
       " 'approached',\n",
       " 'reconciliation',\n",
       " 'archery',\n",
       " 'urology',\n",
       " 'zingy',\n",
       " 'splicing',\n",
       " 'subjunctive',\n",
       " 'cursed',\n",
       " 'enid',\n",
       " 'reports',\n",
       " 'biblical',\n",
       " 'mindless',\n",
       " 'baybrook',\n",
       " 'euphemisms',\n",
       " 'suns',\n",
       " 'swish',\n",
       " 'euler',\n",
       " 'piano',\n",
       " 'lumbar',\n",
       " 'indoors',\n",
       " 'cited',\n",
       " 'dill',\n",
       " 'anthropomorphized',\n",
       " 'iris',\n",
       " 'radioactivity',\n",
       " 'sixteenth',\n",
       " 'collected',\n",
       " '2000',\n",
       " 'stalker',\n",
       " 'hammering',\n",
       " 'caligula',\n",
       " 'lasso',\n",
       " 'permitted',\n",
       " 'activites',\n",
       " 'digest',\n",
       " 'droids',\n",
       " 'concise',\n",
       " 'violating',\n",
       " 'athens',\n",
       " 'cues',\n",
       " 'overproofed',\n",
       " 'expanded',\n",
       " 'captive',\n",
       " 'tesla',\n",
       " 'microvilli',\n",
       " 'cluster',\n",
       " 'succour',\n",
       " 'jablu',\n",
       " 'undrawn',\n",
       " 'martin',\n",
       " 'laminate',\n",
       " 'unsanitary',\n",
       " 'sickness',\n",
       " 'uncertain',\n",
       " 'leafing',\n",
       " 'nightshade',\n",
       " 'computing',\n",
       " 'structure…',\n",
       " 'digestion',\n",
       " '2009',\n",
       " 'seth',\n",
       " '16th',\n",
       " 'disseminate',\n",
       " '¿dónde',\n",
       " 'enumerates',\n",
       " 'duchy',\n",
       " 'lending',\n",
       " 'nourishing',\n",
       " 'pineapple',\n",
       " 'sexting',\n",
       " 'labelled',\n",
       " 'breading',\n",
       " 'pkshhhh',\n",
       " 'fortuitous',\n",
       " 'catastrophe',\n",
       " 'wooh',\n",
       " 'informative',\n",
       " 'randomly',\n",
       " 'nitpick',\n",
       " 'jabir',\n",
       " 'stems',\n",
       " 'encourages',\n",
       " 'butters',\n",
       " 'crossroads',\n",
       " 'apparel',\n",
       " 'masturbating',\n",
       " 'eurydice',\n",
       " 'galaxies',\n",
       " 'criticising',\n",
       " 'raggediness',\n",
       " 'vacuuming',\n",
       " 'employees',\n",
       " 'keteers',\n",
       " 'fluency',\n",
       " 'farther',\n",
       " 'psychologism',\n",
       " 'predatory',\n",
       " 'spelunking',\n",
       " 'neeeeeoooooowwwww',\n",
       " 'transported',\n",
       " 'hillbilly',\n",
       " 'cardinal',\n",
       " 'sterilize',\n",
       " 'tacs',\n",
       " 'agreements',\n",
       " 'straightened',\n",
       " 'adler',\n",
       " 'folly',\n",
       " 'decker',\n",
       " 'crikey',\n",
       " 'crusader',\n",
       " '“frankly',\n",
       " 'illegally',\n",
       " 'wisest',\n",
       " 'chamber',\n",
       " 'mauled',\n",
       " 'readers',\n",
       " 'peeks',\n",
       " 'han',\n",
       " 'duplicated',\n",
       " 'zai',\n",
       " 'forfeit',\n",
       " 'dives',\n",
       " 'misleading',\n",
       " 'mai',\n",
       " 'gaining',\n",
       " 'balrog',\n",
       " 'egomaniac',\n",
       " 'chaser',\n",
       " 'chamomile',\n",
       " 'havoc',\n",
       " 'makh',\n",
       " 'kingman',\n",
       " 'slick',\n",
       " 'quell',\n",
       " 'settlers',\n",
       " 'flogged',\n",
       " 'punishable',\n",
       " 'sluggishly',\n",
       " 'briquettes',\n",
       " 'evergreen',\n",
       " 'protein',\n",
       " 'enacts',\n",
       " 'december',\n",
       " 'spaced',\n",
       " 'discredited',\n",
       " 'planted',\n",
       " 'impart',\n",
       " '350',\n",
       " 'drafting',\n",
       " 'gabby',\n",
       " 'bloweth',\n",
       " 'plethora',\n",
       " 'overlapping',\n",
       " 'drool',\n",
       " 'fellows',\n",
       " 'reseda',\n",
       " 'charade',\n",
       " 'helmholtz',\n",
       " 'humbly',\n",
       " 'superliner',\n",
       " 'roundtable',\n",
       " 'fuse',\n",
       " 'dumbed',\n",
       " 'temporal',\n",
       " 'preferable',\n",
       " 'embarked',\n",
       " 'hollowed',\n",
       " 'graders',\n",
       " 'glenoid',\n",
       " 'replaces',\n",
       " 'tyranny',\n",
       " 'pestilence',\n",
       " 'midterm',\n",
       " 'barren',\n",
       " 'agricultural',\n",
       " 'retracted',\n",
       " 'entrusted',\n",
       " 'conspirators',\n",
       " 'preparedness',\n",
       " 'reverend',\n",
       " 'colourless',\n",
       " 'marshal',\n",
       " 'requirement',\n",
       " 'buick',\n",
       " 'auditory',\n",
       " 'mastered',\n",
       " 'fondest',\n",
       " 'ravaging',\n",
       " 'benefit…',\n",
       " 'producing',\n",
       " 'paralysis',\n",
       " 'celebratory',\n",
       " 'peripheral',\n",
       " 'faddle',\n",
       " 'paul',\n",
       " 'surefire',\n",
       " 'welfare',\n",
       " 'deceit',\n",
       " 'commands',\n",
       " 'daleks',\n",
       " 'repaint',\n",
       " 'licitum',\n",
       " 'advancing',\n",
       " 'contractual',\n",
       " 'pipes',\n",
       " 'mcfly',\n",
       " 'rooted',\n",
       " 'stated',\n",
       " 'eerie',\n",
       " 'flatware',\n",
       " 'fl',\n",
       " 'mutilated',\n",
       " 'kadhai',\n",
       " 'intention',\n",
       " 'triptych',\n",
       " 'institutions',\n",
       " 'instruments',\n",
       " 'fallopian',\n",
       " 'chews',\n",
       " 'tit',\n",
       " 'psychotherapy',\n",
       " 'restate',\n",
       " 'retina',\n",
       " 'deception',\n",
       " 'flawed',\n",
       " 'surfboard',\n",
       " 'selenium',\n",
       " 'export',\n",
       " 'libido',\n",
       " 'amorous',\n",
       " 'proofed',\n",
       " 'leaky',\n",
       " 'restrained',\n",
       " 'clutching',\n",
       " '74',\n",
       " 'consistent',\n",
       " 'pinworms',\n",
       " 'forts',\n",
       " 'flowchart',\n",
       " 'dispatcher',\n",
       " 'streptococcus',\n",
       " 'shui',\n",
       " 'giacomo',\n",
       " 'streetcars',\n",
       " 'consequences',\n",
       " 'bandstand',\n",
       " 'rigid',\n",
       " 'handbook',\n",
       " 'candid',\n",
       " 'eliot',\n",
       " 'ouchies',\n",
       " 'squabbling',\n",
       " 'penalty',\n",
       " 'multiplying',\n",
       " 'farfetched',\n",
       " 'bom',\n",
       " 'immortalized',\n",
       " 'hoverboard',\n",
       " 'pizzas',\n",
       " 'babble',\n",
       " 'absence',\n",
       " 'fermion',\n",
       " 'noteworth',\n",
       " 'rabeliechtli',\n",
       " 'petroleum',\n",
       " 'competence',\n",
       " 'startles',\n",
       " 'hometown',\n",
       " 'numerator',\n",
       " 'perturbative',\n",
       " 'picnics',\n",
       " 'washington',\n",
       " 'fiendishly',\n",
       " 'hears',\n",
       " 'succeeded',\n",
       " 'underpinnings',\n",
       " 'affairs',\n",
       " 'kal',\n",
       " 'shivers',\n",
       " 'heartthrob',\n",
       " 'superstitious',\n",
       " 'teller',\n",
       " 'hoe',\n",
       " 'tubs',\n",
       " 'ovulation',\n",
       " 'humbling',\n",
       " 'retraction',\n",
       " 'rescind',\n",
       " 'toli',\n",
       " 'humorously',\n",
       " 'xie',\n",
       " 'recorded',\n",
       " 'shreds',\n",
       " 'raucous',\n",
       " 'retention',\n",
       " 'companies',\n",
       " 'riemann',\n",
       " 'amazingly',\n",
       " 'removable',\n",
       " 'thusly',\n",
       " 'seamstress',\n",
       " 'ebony',\n",
       " 'remarks',\n",
       " 'snatchers',\n",
       " 'relaxer',\n",
       " 'eloquence',\n",
       " 'pilot',\n",
       " 'arroganto',\n",
       " 'bartenders',\n",
       " 'tightening',\n",
       " 'manners',\n",
       " 'arcade',\n",
       " 'guzzle',\n",
       " 'insufficiently',\n",
       " 'loathes',\n",
       " 'unpredictable',\n",
       " 'sh…',\n",
       " 'unsympathetic',\n",
       " 'carving',\n",
       " 'reassign',\n",
       " 'telematics',\n",
       " 'navel',\n",
       " 'bubbula',\n",
       " 'copulate',\n",
       " 'ryp',\n",
       " 'substantial',\n",
       " 'conversationalists',\n",
       " 'uncoordinated',\n",
       " 'reckoning',\n",
       " 'malls',\n",
       " 'sipping',\n",
       " 'achieving',\n",
       " 'antoine',\n",
       " 'quests',\n",
       " 'continually',\n",
       " 'passages',\n",
       " 'transferable',\n",
       " 'immaculate',\n",
       " 'nonchalant',\n",
       " 'projectile',\n",
       " 'cater',\n",
       " '‘er',\n",
       " 'amongst',\n",
       " 'evident',\n",
       " 'fondling',\n",
       " 'discounted',\n",
       " 'vocation',\n",
       " 'carrier',\n",
       " 'mater',\n",
       " '‘arrah',\n",
       " 'beguiling',\n",
       " 'seatbelts',\n",
       " 'mocked',\n",
       " 'hindbrain',\n",
       " 'unfolded',\n",
       " 'contrary',\n",
       " 'commensurate',\n",
       " 'fleck',\n",
       " 'copernicus',\n",
       " 'unfriend',\n",
       " 'schmo',\n",
       " 'dodging',\n",
       " 'giuseppe',\n",
       " 'morsel',\n",
       " 'yoctometers',\n",
       " '165',\n",
       " 'coop',\n",
       " 'aversions',\n",
       " 'edifices',\n",
       " 'dwarves',\n",
       " 'unqualified',\n",
       " 'wrecker',\n",
       " 'freckles',\n",
       " 'distilled',\n",
       " 'niece',\n",
       " 'monolithic',\n",
       " 'hirschsprung',\n",
       " 'alterations',\n",
       " 'canine',\n",
       " 'nordic',\n",
       " 'divvied',\n",
       " 'skyrocket',\n",
       " 'manufacturer',\n",
       " 'sssshhhh',\n",
       " 'refusal',\n",
       " 'labourers',\n",
       " 'pm',\n",
       " 'ribbing',\n",
       " 'baggy',\n",
       " 'september',\n",
       " 'amc',\n",
       " 'prospect',\n",
       " 'palpatine',\n",
       " 'ceti',\n",
       " 'posing',\n",
       " 'distinction',\n",
       " 'proceeding',\n",
       " 'scrolls',\n",
       " 'halbert',\n",
       " 'bounds',\n",
       " 'sociopathic',\n",
       " 'pubescent',\n",
       " 'reprogrammed',\n",
       " '“cohabitation”',\n",
       " 'hardware',\n",
       " 'demotion',\n",
       " 'inscrutable',\n",
       " 'interjection',\n",
       " 'inspector',\n",
       " 'hallucinogenics',\n",
       " 'nameless',\n",
       " 'derives',\n",
       " 'showman',\n",
       " 'prize…',\n",
       " 'disfigured',\n",
       " 'staphylococcus',\n",
       " 'necking',\n",
       " 'nadoolman',\n",
       " 'damaged…',\n",
       " 'sparring',\n",
       " 'thugs',\n",
       " 'greaseboards',\n",
       " 'equilibrium',\n",
       " 'probability',\n",
       " 'alphabetized',\n",
       " 'subtlety',\n",
       " 'incisors',\n",
       " 'warlock',\n",
       " 'dag',\n",
       " 'gravelly',\n",
       " 'concessions',\n",
       " 'callous',\n",
       " '…tion',\n",
       " 'ipecac',\n",
       " 'clairvoyance',\n",
       " 'undoubtedly',\n",
       " 'demonstrating',\n",
       " 'docked',\n",
       " 'bombing',\n",
       " 'candyland',\n",
       " 'industry',\n",
       " 'tidbits',\n",
       " 'watering',\n",
       " 'genius…',\n",
       " 'moderately',\n",
       " 'administer',\n",
       " 'hemispheres',\n",
       " 'gleaned',\n",
       " 'jungian',\n",
       " 'igniting',\n",
       " 'monrovia',\n",
       " 'plover',\n",
       " 'vision',\n",
       " 'enquiry',\n",
       " 'polyhedral',\n",
       " 'considerations',\n",
       " 'secretly',\n",
       " 'aficionado',\n",
       " 'croutons',\n",
       " 'mes',\n",
       " 'progressing',\n",
       " 'lunchtime',\n",
       " 'incense',\n",
       " 'cowpokes',\n",
       " 'kunta',\n",
       " 'boone',\n",
       " 'traitor',\n",
       " 'lurks',\n",
       " 'faa',\n",
       " 'weakened',\n",
       " '32',\n",
       " 'fumes',\n",
       " 'bad…',\n",
       " 'emissary',\n",
       " 'unanimous',\n",
       " 'camomile',\n",
       " 'asians',\n",
       " 'tlhej',\n",
       " 'strangled',\n",
       " 'concrete”',\n",
       " 'carbonate',\n",
       " 'chillies',\n",
       " 'tandoori',\n",
       " 'perlmutter',\n",
       " 'preening',\n",
       " 'apt',\n",
       " 'luna',\n",
       " 'possessed',\n",
       " 'fun…',\n",
       " 'challenged',\n",
       " 'byes',\n",
       " 'enact',\n",
       " 'cartesian',\n",
       " 'krengjai',\n",
       " 'communications',\n",
       " 'beverages',\n",
       " 'northern',\n",
       " 'limit',\n",
       " 'wisconsin',\n",
       " 'arduous',\n",
       " '1980s',\n",
       " 'traitors',\n",
       " 'halfsies',\n",
       " 'emblazon',\n",
       " '41',\n",
       " 'restraint',\n",
       " 'first…',\n",
       " 'lobotomy',\n",
       " 'theorist',\n",
       " 'ladybugs',\n",
       " 'particulate',\n",
       " 'propter',\n",
       " 'ethernet',\n",
       " 'rodent',\n",
       " 'billed',\n",
       " 'requirements',\n",
       " 'verses',\n",
       " 'jackie',\n",
       " 'ziggy',\n",
       " 'fascinated',\n",
       " 'grotesque',\n",
       " 'content…',\n",
       " 'suture',\n",
       " 'proctologist',\n",
       " 'notified',\n",
       " 'railways',\n",
       " 'pomegranate',\n",
       " 'yoke',\n",
       " 'dressier',\n",
       " '28th',\n",
       " 'millimetre',\n",
       " 'rancher',\n",
       " 'disc',\n",
       " 'dermatitis',\n",
       " 'relies',\n",
       " 'sturdy',\n",
       " 'toxic',\n",
       " 'hatched',\n",
       " 'pea',\n",
       " 'mobius',\n",
       " 'hyperthyroidism',\n",
       " 'warts',\n",
       " 'heartfelt',\n",
       " 'scray',\n",
       " 'hickey',\n",
       " 'sacrificing',\n",
       " 'catfish',\n",
       " 'afflicted',\n",
       " 'resemble',\n",
       " 'anthropologists',\n",
       " 'babysitting',\n",
       " 'etch',\n",
       " 'condensate',\n",
       " 'barbarian',\n",
       " 'banter',\n",
       " 'entity',\n",
       " 'frivolity',\n",
       " '“grown',\n",
       " 'baskets',\n",
       " 'duke',\n",
       " 'finicky',\n",
       " 'tic',\n",
       " 'manufactured',\n",
       " 'incident',\n",
       " 'irresponsible',\n",
       " 'penalties',\n",
       " 'testers',\n",
       " 'proximal',\n",
       " 'contradistinction',\n",
       " 'feedback',\n",
       " 'entrepreneurial',\n",
       " 'gameygamer75',\n",
       " 'helper',\n",
       " 'housed',\n",
       " 'mufasa',\n",
       " 'frost…',\n",
       " 'amigo',\n",
       " 'runny',\n",
       " 'pete',\n",
       " 'hawkeye',\n",
       " 'unsatisfactory',\n",
       " 'myth',\n",
       " 'stifled',\n",
       " 'hoth',\n",
       " 'discourteous',\n",
       " 'deduce',\n",
       " 'faulted',\n",
       " 'berserk',\n",
       " 'resetting',\n",
       " 'speechless',\n",
       " 'tissue',\n",
       " 'fraudville',\n",
       " 'lanes',\n",
       " 'dreamers',\n",
       " 'meemaws',\n",
       " 'moot',\n",
       " '71',\n",
       " 'maiden',\n",
       " 'traveled',\n",
       " 'artisanal',\n",
       " 'swarming',\n",
       " 'intercontinental',\n",
       " 'flagpole',\n",
       " 'grammatical',\n",
       " 'abnormalities',\n",
       " 'bir',\n",
       " 'bouffant',\n",
       " 'morality',\n",
       " 'deployment',\n",
       " 'lalande',\n",
       " 'supersoldiers',\n",
       " 'stateless',\n",
       " 'mobster',\n",
       " 'trapper',\n",
       " 'armenia',\n",
       " 'finalize',\n",
       " '47',\n",
       " 'jean',\n",
       " 'streaming',\n",
       " 'gambling',\n",
       " 'peaked',\n",
       " 'disinclination',\n",
       " 'frivolous',\n",
       " 'albeit',\n",
       " 'causal',\n",
       " 'fascism',\n",
       " 'funnin',\n",
       " 'requiring',\n",
       " 'siblings',\n",
       " 'manure',\n",
       " 'smugglers',\n",
       " 'stretched',\n",
       " 'retrieval',\n",
       " 'rumba',\n",
       " 'lined',\n",
       " 'perkiness',\n",
       " 'refocused',\n",
       " 'conundrum',\n",
       " 'deceased',\n",
       " 'callipers',\n",
       " 'sears',\n",
       " 'unraveling',\n",
       " 'humvee',\n",
       " 'snickering',\n",
       " 'questionable',\n",
       " 'nodlehs',\n",
       " 'repurposes',\n",
       " 'regaled',\n",
       " 'marco',\n",
       " 'irrational',\n",
       " 'chap',\n",
       " 'unattended”',\n",
       " 'sneezy',\n",
       " 'contra',\n",
       " 'contractually',\n",
       " 'aramis',\n",
       " 'grossinger',\n",
       " 'surpasses',\n",
       " 'luminescence',\n",
       " 'pitted',\n",
       " 'cosies',\n",
       " 'families',\n",
       " 'effusive',\n",
       " 'grande',\n",
       " 'dunking',\n",
       " 'reshaped',\n",
       " 'dietary',\n",
       " 'marauders',\n",
       " 'spun',\n",
       " 'rated',\n",
       " '“waltz”',\n",
       " 'necromancer',\n",
       " 'hypocrisy',\n",
       " 'substitutes',\n",
       " 'browse',\n",
       " 'curled',\n",
       " 'dubbed',\n",
       " 'rankest',\n",
       " 'buffer',\n",
       " 'allotted',\n",
       " 'sleek',\n",
       " 'dreamer',\n",
       " 'ectoplasmic',\n",
       " 'kool',\n",
       " 'measly',\n",
       " 'ringer',\n",
       " 'polecat',\n",
       " 'trails',\n",
       " 'wail',\n",
       " 'tinfoil',\n",
       " 'organized',\n",
       " 'doubtful',\n",
       " 'vantage',\n",
       " 'unnerving',\n",
       " 'blowout',\n",
       " 'gigolo',\n",
       " 'refuge',\n",
       " 'unfit',\n",
       " 'anomalies',\n",
       " 'parliamentary',\n",
       " 'hula',\n",
       " 'sawyer',\n",
       " 'tmake',\n",
       " 'inferior',\n",
       " 'infractions',\n",
       " 'metabolizing',\n",
       " 'schoolyard',\n",
       " 'roaming',\n",
       " 'strengthen',\n",
       " 'annihilation',\n",
       " 'braille',\n",
       " 'hexagonal…',\n",
       " 'deceptive',\n",
       " 'tad',\n",
       " 'jug',\n",
       " 'heritage',\n",
       " 'guardians',\n",
       " 'anticipated',\n",
       " 'yogis',\n",
       " 'thorax',\n",
       " 'usage',\n",
       " 'assure',\n",
       " 'reassembly',\n",
       " 'genders',\n",
       " 'planter',\n",
       " 'procreating',\n",
       " 'supernatural',\n",
       " 'procedures',\n",
       " 'accusing',\n",
       " 'commonly',\n",
       " 'segregation',\n",
       " 'teens',\n",
       " 'taboo',\n",
       " 'ambivalence',\n",
       " 'geezers',\n",
       " 'aligns',\n",
       " 'inspire',\n",
       " 'pedestal',\n",
       " 'ward',\n",
       " 'savagery',\n",
       " 'cinderblock',\n",
       " 'goldfarb',\n",
       " 'cornhusking',\n",
       " 'contractor',\n",
       " 'intensified',\n",
       " 'spay',\n",
       " 'heartless',\n",
       " 'alphabetical',\n",
       " 'magnesium',\n",
       " 'partition',\n",
       " 'murderers',\n",
       " 'feast',\n",
       " 'defective',\n",
       " 'darnedest',\n",
       " 'zucchini',\n",
       " 'tinier',\n",
       " 'memorabilia',\n",
       " 'wolfgang',\n",
       " 'lori',\n",
       " 'plunged',\n",
       " 'advantages',\n",
       " 'frigid',\n",
       " 'nighclub',\n",
       " 'proclaimed',\n",
       " 'crummy',\n",
       " 'petite',\n",
       " 'magpie',\n",
       " 'hightail',\n",
       " 'weaning',\n",
       " 'doodads',\n",
       " 'lingual',\n",
       " 'acknowledgement',\n",
       " 'joined',\n",
       " 'anodised',\n",
       " 'fornication',\n",
       " 'sleeper',\n",
       " 'productivity',\n",
       " '“möchtest',\n",
       " 'pakistan',\n",
       " 'pursuant',\n",
       " 'scavenging',\n",
       " 'humerus',\n",
       " 'contained',\n",
       " 'unaware',\n",
       " 'wedgied',\n",
       " 'continuation',\n",
       " 'cycle',\n",
       " 'hairless',\n",
       " 'conformational',\n",
       " 'futility',\n",
       " 'april',\n",
       " 'nth',\n",
       " 'eeg',\n",
       " 'null',\n",
       " 'hominymic',\n",
       " 'indemnified',\n",
       " 'shaggy',\n",
       " 'plunk',\n",
       " 'offices',\n",
       " 'analysing',\n",
       " 'wheelbase',\n",
       " 'hardwood',\n",
       " 'blazing',\n",
       " 'mutilation',\n",
       " 'unimportant',\n",
       " 'supergravity',\n",
       " 'hooey',\n",
       " 'scrappy',\n",
       " 'nervousness',\n",
       " 'reassuring',\n",
       " 'stubble',\n",
       " 'insinuate',\n",
       " 'refreshment',\n",
       " 'finder',\n",
       " 'conceal',\n",
       " 'fester',\n",
       " 'standstill',\n",
       " 'nab',\n",
       " 'genes',\n",
       " 'extensively',\n",
       " 'prophylactic',\n",
       " 'nelly',\n",
       " 'libre',\n",
       " 'trainiac',\n",
       " 'actions',\n",
       " 'consensus',\n",
       " 'organizer',\n",
       " 'kumquat',\n",
       " 'lingerie',\n",
       " 'santeriasuzy37',\n",
       " 'linguistics',\n",
       " 'wicket',\n",
       " 'indigestion',\n",
       " 'circumvent',\n",
       " '1863',\n",
       " 'defensive',\n",
       " 'massively',\n",
       " 'blaster',\n",
       " 'soot',\n",
       " 'amounts',\n",
       " 'caped',\n",
       " 'antibiotic',\n",
       " 'formal',\n",
       " 'biscuit',\n",
       " 'fertilization',\n",
       " 'polymerised',\n",
       " 'ferments',\n",
       " 'kerfuffle',\n",
       " 'rhenium',\n",
       " 'mache',\n",
       " 'dipoles',\n",
       " 'pillage',\n",
       " 'richie',\n",
       " 'molybdenum',\n",
       " 'collaborate',\n",
       " 'dispatched',\n",
       " 'vistas',\n",
       " 'whisks',\n",
       " 'accommodate',\n",
       " 'microsoft',\n",
       " 'coalesce',\n",
       " 'della',\n",
       " 'affordable',\n",
       " 'expanding',\n",
       " 'paragraph',\n",
       " 'shattering',\n",
       " 'erotically',\n",
       " 'derisively',\n",
       " 'improper',\n",
       " 'choir',\n",
       " 'mithra',\n",
       " '1935',\n",
       " 'gradation',\n",
       " 'perusing',\n",
       " 'stagnant',\n",
       " 'ps2',\n",
       " 'fleming',\n",
       " 'dinfast',\n",
       " 'blart',\n",
       " 'smuggling',\n",
       " 'candies',\n",
       " 'stanislavski',\n",
       " 'explorer',\n",
       " 'palatable',\n",
       " 'archduchy',\n",
       " 'dutch',\n",
       " 'derision',\n",
       " 'carton',\n",
       " 'shakers',\n",
       " 'snippets',\n",
       " 'katto',\n",
       " 'describes',\n",
       " 'spectacular',\n",
       " 'sezchuan',\n",
       " 'gobble',\n",
       " 'unleashed',\n",
       " 'pontifex',\n",
       " 'unrepeatable',\n",
       " 'childlike',\n",
       " '“a',\n",
       " 'numbingly',\n",
       " 'inexplicable',\n",
       " 'elaborate',\n",
       " 'patootie',\n",
       " 'manga',\n",
       " 'residence',\n",
       " ...}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_sheldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40264    False\n",
       "40265    False\n",
       "40266    False\n",
       "40267    False\n",
       "40268    False\n",
       "         ...  \n",
       "51180    False\n",
       "51181     True\n",
       "51182    False\n",
       "51183    False\n",
       "51184    False\n",
       "Length: 10921, dtype: bool"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_sheldon(row):\n",
    "    for word in row['line'].split():\n",
    "        if word in unique_sheldon:\n",
    "            return True\n",
    "    return False\n",
    "pred = df_test.apply(predict_sheldon, axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7820712388975368"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred == (df_test['character'] == 'Sheldon'))/len(df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
